# AI / Human 文章偵測器 (範例專案)

簡要說明：本專案示範如何訓練一個簡單的二元分類器（TF-IDF + Logistic Regression）來判斷文本是由 AI 生產還是人類撰寫，並用 Streamlit 提供線上互動介面。

專案結構：

- `data/`：放置資料集 `ai_human_text.csv`（請自行從 Kaggle 下載並放入）
- `models/`：訓練後的模型會儲存在此（`ai_detector.joblib`）
- `src/train_model.py`：訓練模型的腳本
- `streamlit_app.py`：Streamlit 主程式，用於部署和互動
- `requirements.txt`：執行所需套件

快速上手：

1. 安裝套件

```powershell
pip install -r requirements.txt
```

2. 準備資料

將你從 Kaggle 下載的 CSV 放進 `data/` 資料夾，並命名為 `ai_human_text.csv`。CSV 需包含兩個欄位：

- `text`：文章內容（字串）
- `label`：標籤，值為 `AI` 或 `Human`

若欄位名稱不同，請修改 `src/train_model.py` 裡的欄位對應。

3. 訓練模型

```powershell
python src/train_model.py
```

訓練完成後會在 `models/ai_detector.joblib` 產生模型檔。

4. 啟動 Streamlit App

```powershell
streamlit run streamlit_app.py
```

5. 部署到 Streamlit Cloud

- Push 整個專案到 GitHub
- 登入 https://streamlit.io，選擇 "New app" 並連結你的 repo
- 指定 `streamlit_app.py` 為主檔並部署

資料來源建議（作業可寫）：

- Kaggle: "AI vs Human Text Dataset" 或 "ChatGPT Classification Dataset"

報告建議包含：

- 資料集來源與大小
- 模型架構（TF-IDF + Logistic Regression）
- 評估指標（Accuracy、Precision、Recall、F1、ROC-AUC）
- 訓練結果（`src/train_model.py` 會打印 `classification_report` 與 ROC-AUC）
- 部署連結（Streamlit App URL）

若要我幫你：

- 調整程式以配合你手上的 CSV 欄位名稱（告訴我欄位名稱）
- 幫你自動化打包並產生一個範例小資料（供 demo 用）
- 提供推上 GitHub 與在 Streamlit Cloud 部署的逐步指令
Project: CWA Weather & Movie Crawlers

Contents
- `weather_crawler.py` : downloads CWA F-A0010-001 JSON and saves parsed temps into `data.db` (SQLite)
- `streamlit_app.py`  : Streamlit app that reads `data.db` and displays the `weather` table
- `movie_crawler.py`  : crawls https://ssr1.scrape.center pages 1..10 and writes `movie.csv`
- `requirements.txt`  : Python dependencies

Part 1 — Weather (CWA JSON -> SQLite -> Streamlit)
1. Install requirements (recommended in a venv):

```powershell
python -m venv .venv; .\.venv\Scripts\Activate.ps1; pip install -r requirements.txt
```

2. Run the weather crawler to download and populate the SQLite DB:

```powershell
python weather_crawler.py --apikey CWA-1FFDDAEC-161F-46A3-BE71-93C32C52829F --db data.db
```

This will create `data.db` with a table `weather` containing columns: `id, location, min_temp, max_temp, description`.

3. Run the Streamlit app to view the table:

```powershell
streamlit run streamlit_app.py
```

Open the local Streamlit URL (usually http://localhost:8501) and take a screenshot showing the displayed table for submission.

Part 2 — Movie crawler (10 pages)
1. Run the movie crawler:

```powershell
python movie_crawler.py
```

This will create `movie.csv` containing columns `title,image,rating,types`.

Notes & Troubleshooting
- The `weather_crawler.py` contains heuristics to find temperature values in the CWA JSON dataset `F-A0010-001`. If the structure differs, the script prints top-level keys for debugging.
- If `streamlit_app.py` shows "No data found", run `weather_crawler.py` first.
- If you need to use your own API key, pass `--apikey` to `weather_crawler.py`.

Deliverables to submit (suggested):
- `weather_crawler.py` (source)
- `data.db` (SQLite file generated by the script)
- `streamlit_app.py` (source)
- Screenshot of Streamlit showing the table
- `movie_crawler.py` (source)
- `movie.csv` (generated by the script)

---

模型上傳與 Streamlit Cloud 的建議處理

- 不建議把訓練好的 `models/ai_detector.joblib` 直接放在公開的 Git repository（檔案較大且非原始碼）。
- 建議把模型檔上傳到 GitHub Release（或其他能取得直鏈的雲端儲存，如 Google Drive / Dropbox），然後在 Streamlit App 啟動時下載模型。

如何建立 GitHub Release（手動）：

1. 到你在 GitHub 的 repo 頁面 → 點選 `Releases` → `Draft a new release`。
2. 填寫 tag（例如 `v1.0`）、標題與描述。
3. 在 `Attach binaries by dropping them here or selecting them.` 區塊上傳 `ai_detector.joblib`。
4. Publish release，複製附件（Release asset）的 `Download` 連結。

在 Streamlit Cloud 設定模型 URL：

1. 到 Streamlit Cloud 的你的 app → Settings → Secrets。新增一個 secret key 叫 `MODEL_URL`，value 填 Release 的下載 URL（或其他可直連檔案的 URL）。
2. 部署的 app 在啟動時若找不到本地模型會顯示下載按鈕，按下後即可下載並儲存到 `models/ai_detector.joblib`。

本地如何測試下載流程（如果你先把模型上傳到某個 URL）：

```powershell
cd "D:\OneDrive\OneDrive - 中興大學\HW5\ai-human-detector-clean"
# 設定環境變數（範例，PowerShell）
$env:MODEL_URL = "https://github.com/<you>/<repo>/releases/download/v1.0/ai_detector.joblib"
streamlit run streamlit_app.py
```

備註：`streamlit_app.py` 已支援從 `st.secrets['MODEL_URL']` 或環境變數 `MODEL_URL` 下載模型，若找不到模型會顯示下載選項。

