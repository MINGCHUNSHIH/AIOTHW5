import streamlit as st
import joblib
import numpy as np
import os


@st.cache_resource
def load_model():
    model_path = os.path.join("models", "ai_detector.joblib")
    return joblib.load(model_path)


st.set_page_config(
    page_title="AI / Human æ–‡ç« åµæ¸¬å™¨",
    page_icon="ğŸ¤–",
)

st.title("ğŸ¤– AI vs Human æ–‡ç« åµæ¸¬å™¨")
st.write("è¼¸å…¥ä¸€æ®µæ–‡å­—ï¼Œæ¨¡å‹æœƒä¼°è¨ˆå®ƒæ˜¯ **AI ç”Ÿæˆ** é‚„æ˜¯ **äººé¡æ’°å¯«**ã€‚")

# Load model if available
model = None
try:
    model = load_model()
except Exception as e:
    st.warning(f"æ¨¡å‹è¼‰å…¥å¤±æ•—æˆ–ä¸å­˜åœ¨ï¼š{e}\nè«‹å…ˆåŸ·è¡Œ `python src/train_model.py` ä¾†è¨“ç·´ä¸¦ç”¢ç”Ÿ `models/ai_detector.joblib`ã€‚")


# User input
default_text = "è«‹åœ¨é€™è£¡è²¼ä¸Šä½ æƒ³æª¢æ¸¬çš„æ–‡ç« å…§å®¹..."

user_text = st.text_area(
    "è¼¸å…¥æˆ–è²¼ä¸Šæ–‡å­—ï¼š",
    height=220,
    placeholder=default_text
)

if st.button("é–‹å§‹åˆ†æ"):
    if not user_text.strip():
        st.warning("è«‹å…ˆè¼¸å…¥ä¸€äº›æ–‡å­—å†æŒ‰ä¸‹æŒ‰éˆ•ã€‚")
    else:
        if model is None:
            st.error("æ¨¡å‹å°šæœªè¼‰å…¥ã€‚è«‹å…ˆåŸ·è¡Œ `python src/train_model.py` ä¸¦ç¢ºèª `models/ai_detector.joblib` å­˜åœ¨ã€‚")
        else:
            proba = model.predict_proba([user_text])[0]
            classes = model.classes_

            # æ‰¾å‡º "AI" é€™ä¸€é¡çš„ä½ç½®ï¼Œå¦‚æœæ‰¾ä¸åˆ°å°±ç”¨ index 0 ä½œç‚º fallback
            try:
                ai_idx = int(np.where(classes == "AI")[0][0])
                ai_prob = float(proba[ai_idx])
            except Exception:
                ai_prob = float(proba[0])

            human_prob = 1.0 - ai_prob

            col1, col2 = st.columns(2)
            with col1:
                st.metric("AI ç”Ÿæˆçš„æ©Ÿç‡", f"{ai_prob * 100:.1f} %")
            with col2:
                st.metric("Human æ’°å¯«çš„æ©Ÿç‡", f"{human_prob * 100:.1f} %")

            st.write("---")
            st.write("ğŸ” **è¦–è¦ºåŒ–ï¼šAI æ©Ÿç‡æ¢**")
            st.progress(ai_prob)

            with st.expander("é¡¯ç¤ºæ¨¡å‹å…§éƒ¨è³‡è¨Šï¼ˆé¸ç”¨ï¼‰"):
                st.write("æ¨¡å‹ä½¿ç”¨ TF-IDF + Logistic Regression é€²è¡Œåˆ†é¡ã€‚")
                try:
                    vectorizer = model.named_steps["tfidf"]
                    vocab_size = len(vectorizer.vocabulary_)
                    st.write(f"ç›®å‰ TF-IDF è©å½™æ•¸é‡ï¼šç´„ **{vocab_size}** å€‹ç‰¹å¾µã€‚")
                except Exception:
                    st.write("ç„¡æ³•å–å¾— TF-IDF ç‰¹å¾µè³‡è¨Šã€‚")
